{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c382de",
   "metadata": {},
   "source": [
    "# Classification non-supervisée de questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaa521",
   "metadata": {},
   "source": [
    "## Import des librairies et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c07f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc586ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56bfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "for word in ['what', 'how', 'where', 'who', 'which'] :\n",
    "    stop_words.append(word)\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184f48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7740bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"top_10_tags.txt\", \"r\")\n",
    "top_10_tags = file.read()\n",
    "top_10_tags = list(top_10_tags.split('\\n')[:-1])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b8ae4",
   "metadata": {},
   "source": [
    "## Échantillonnage et nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['Title']\n",
    "text_spl = text.sample(frac = 0.25).reset_index(drop = True)\n",
    "text_spl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Textes bruts :\")\n",
    "print(\"\")\n",
    "print(text_spl[:11])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Textes nettoyés par Gensim :\")\n",
    "print(\"\")\n",
    "print(text_spl[:11].apply(simple_preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags = [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]) :\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable = [\"parser\", \"ner\"])\n",
    "    texts_out = []\n",
    "    for text in texts :\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc :\n",
    "            if token.orth_ in top_10_tags :\n",
    "                new_text.append(token.orth_)\n",
    "            else :\n",
    "                if token.pos_ in allowed_postags :\n",
    "                    new_text.append(token.lemma_)\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb510f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Textes bruts :\")\n",
    "print(\"\")\n",
    "print(text_spl[:11])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Textes nettoyés par spaCy :\")\n",
    "print(\"\")\n",
    "print(pd.Series(lemmatization(text_spl[:11])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text) :\n",
    "\n",
    "    \"\"\"\" Nettoyage du texte :\n",
    "    passage au minuscule\n",
    "    suppression du code éventuel du texte que l'on stocke dans une variable 'code'\n",
    "    suppression et du contenu des balises autres que p (script, alt, ...)\n",
    "    suppression des balises html\n",
    "    conservation des textes labellisés par les top 10 tags uniquement\n",
    "    suppression de la ponctuation, des chiffres,\n",
    "    et des stopwords\n",
    "    lemmatisation par spaCy \"\"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    soup = BeautifulSoup(text)\n",
    "    \n",
    "    if soup.find(\"code\") :        \n",
    "        code = soup.find(\"code\").get_text()\n",
    "        soup.find('code').clear()\n",
    "    text_wo_tags = soup.get_text()\n",
    "    \n",
    "    for i in range(1, len(text_wo_tags)) :\n",
    "        if text_wo_tags[i-1] == 'c' and text_wo_tags[i] == '#' :\n",
    "            text_wo_tags = text_wo_tags.replace(text_wo_tags[i], 'sharp')\n",
    "    \n",
    "    token_list = nltk.word_tokenize(text_wo_tags)\n",
    "    \n",
    "    new_text = []\n",
    "    \n",
    "    for token in token_list :\n",
    "        if token in top_10_tags :\n",
    "            new_text.append(token)\n",
    "        elif token not in stop_words :\n",
    "            for char in token :\n",
    "                if char in punctuation or char.isdigit() :\n",
    "                    token = token.replace(char, '')\n",
    "            new_text.append(token)\n",
    "    \n",
    "    lem = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    for token in new_text :\n",
    "        if nltk.pos_tag([token])[0][1].startswith('V') :\n",
    "            index = new_text.index(token)\n",
    "            token_lem = lem.lemmatize(token, pos = 'v')\n",
    "            new_text[index] = new_text[index].replace(token, token_lem)\n",
    "            \n",
    "    new_text = ' '.join(new_text)\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dee0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Textes bruts :\")\n",
    "print(\"\")\n",
    "print(text_spl[:11])\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Textes nettoyés par la fonction créée :\")\n",
    "print(\"\")\n",
    "print(text_spl[:11].apply(preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98df54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text_clean = text_spl.parallel_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_spl = pd.DataFrame(text_spl)\n",
    "text_clean = pd.DataFrame(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, text_spl, on = \"Title\", how = \"right\")\n",
    "data = data.drop(columns = {'Body'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, text_clean], axis = 1)\n",
    "data.columns = ['Title', 'Tags', 'Title_clean'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffaed08",
   "metadata": {},
   "source": [
    "## Classification non-supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ddc4e",
   "metadata": {},
   "source": [
    "### Feature extraction par Bag-of-Words (gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89197d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for doc in text_clean :\n",
    "    words.append(nltk.word_tokenize(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5181f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(words)\n",
    "corpus = []\n",
    "\n",
    "for word in words :\n",
    "    corpus.append(id2word.doc2bow(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a7b31",
   "metadata": {},
   "source": [
    "### Optimisation du nombre de topics (score de cohérence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence_table(corpus, dictionary, list_n):\n",
    "    \n",
    "    coherence_table = []\n",
    "    \n",
    "    for i in list_n :\n",
    "    \n",
    "        lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=i, \n",
    "                                               random_state=100,\n",
    "                                               chunksize=100,\n",
    "                                               passes=10)\n",
    "\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, texts=words, dictionary=id2word, coherence='c_v')\n",
    "\n",
    "        coherence_table.append(coherence_model_lda.get_coherence())\n",
    "\n",
    "    return coherence_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9469f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_topics_range = np.linspace(3, 30, 10)\n",
    "table = coherence_table(corpus, id2word, n_topics_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f182ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(y = table, x = n_topics_range).set(xlabel = \"n_topics\", ylabel = \"Cohérence\")\n",
    "plt.title(\"Score de cohérence du modèle de LDA en fonction du nombre de topics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a39f98",
   "metadata": {},
   "source": [
    "### Clustering par Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40365ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15\n",
    "\n",
    "lda = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7e435",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "gensimvis.prepare(lda, corpus, id2word, mds = 'mmds', R=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563a593",
   "metadata": {},
   "source": [
    "### Extraction des tags trouvés par LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = []\n",
    "\n",
    "for row in lda.show_topics(num_topics = 15) :\n",
    "    for tag in top_10_tags :\n",
    "        if tag in row[1] :\n",
    "            lda_df.append([row[0], tag])\n",
    "            \n",
    "lda_df = pd.DataFrame(lda_df, columns = ['num_cluster', 'tag_lda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.DataFrame(lda_df.groupby('num_cluster')['tag_lda'].apply(list)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_cluster = []\n",
    "\n",
    "for index, row in enumerate(lda[corpus]) :\n",
    "    if len(row) < 15 :\n",
    "        lda_cluster.append([index, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25053b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_cluster = pd.DataFrame(lda_cluster, columns = ['data_index', 'lda_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_cluster = pd.DataFrame(lda_cluster.explode('lda_cluster').explode('lda_cluster')[::2].groupby('data_index')['lda_cluster'].apply(\n",
    "    list)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[lda_cluster['data_index'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abdb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, lda_cluster, left_index = True, right_on = \"data_index\").drop(columns = 'data_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33555ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_topics(data) :\n",
    "\n",
    "    lda_tags = []\n",
    "\n",
    "    for cluster in range(len(lda_df['num_cluster'])) :\n",
    "        if cluster in data :\n",
    "            tmp = []\n",
    "            tmp.append(lda_df.loc[cluster, 'tag_lda'])\n",
    "            tmp = pd.Series(tmp).explode().to_list()\n",
    "            lda_tags = lda_tags + tmp\n",
    "            \n",
    "    return lda_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lda_tags'] = data['lda_cluster'].apply(find_topics)\n",
    "data = data.drop(columns = {'lda_cluster'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
